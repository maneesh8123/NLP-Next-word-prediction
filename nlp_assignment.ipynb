{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70673fec",
   "metadata": {},
   "source": [
    "####  4.\tThe objective is to create a next word prediction for the Malayalam language. When you type on the android keyboard, the possible following words are displayed on the top of the keyboard. Implement a similar functionality for Malayalam. Create a dataset, train and create a language model. Create a script to get user input and print possible next words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "59bd3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data=\"മലയാളം യൂണിക്കോഡും വിക്കീപീഡിയയുംമലയാളം പോലുള്ള ഭാഷകൾക്ക് കമ്പ്യൂട്ടറിൽ എഴുതാനും വായിക്കാനുമുപയോഗിക്കുന്ന ലിപിവ്യവസ്ഥകളിൽ ആദ്യമൊന്നും പൊതുവായ ഒരു മാനദണ്ഡമുണ്ടായിരുന്നില്ല. അതിനാൽ തന്നെ ഇത്തരം ഭാഷയിൽ എഴുതുന്ന ലേഖനങ്ങൾ വായിക്കാൻ പ്രസ്തുത ലേഖനം എഴുതിയ ആൾ ഉപയോഗിച്ച ഫോണ്ടും കമ്പ്യൂട്ടർ വ്യവസ്ഥയും തന്നെ ഉപയോഗിക്കണം എന്ന സ്ഥിതി ആയിരുന്നു. യുണികോഡ് എന്നറിയപ്പെടുന്ന കമ്പ്യൂട്ടർ ലിപിവ്യവസ്ഥ വന്നതോടുകൂടി മലയാളം കമ്പ്യൂട്ടറിനു വഴങ്ങുന്ന ഒന്നായി. മലയാളം (യൂണിക്കോഡ് അക്ഷരവിഭാഗം) സാർ‌വത്രികമായി ഉപയോഗിക്കുവാൻ തുടങ്ങിയതോടെയാണ്‌ മലയാളം വിക്കിപ്പീഡിയ സജീവമായത്.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "7cabca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM,Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "46930697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "മലയാളം യൂണിക്കോഡും വിക്കീപീഡിയയുംമലയാളം പോലുള്ള ഭാഷകൾക്ക് കമ്പ്യൂട്ടറിൽ എഴുതാനും വായിക്കാനുമുപയോഗിക്കുന്ന ലിപിവ്യവസ്ഥകളിൽ ആദ്യമൊന്നും പൊതുവായ ഒരു മാനദണ്ഡമുണ്ടായിരുന്നില്ല. അതിനാൽ തന്നെ ഇത്തരം ഭാഷയിൽ എഴുതുന്ന ലേഖനങ്ങൾ വായിക്കാൻ പ്രസ്തുത ലേഖനം എഴുതിയ ആൾ ഉപയോഗിച്ച ഫോണ്ടും കമ്പ്യൂട്ടർ വ്യവസ്ഥയും തന്നെ ഉപയോഗിക്കണം എന്ന സ്ഥിതി ആയിരുന്നു. യുണികോഡ് എന്നറിയപ്പെടുന്ന കമ്പ്യൂട്ടർ ലിപിവ്യവസ്ഥ വന്നതോടുകൂടി മലയാളം കമ്പ്യൂട്ടറിനു വഴങ്ങുന്ന ഒന്നായി. മലയാളം (യൂണിക്കോഡ് അക്ഷരവിഭാഗം) സാർ‌വത്രികമായി ഉപയോഗിക്കുവാൻ തുടങ്ങിയതോടെയാണ്‌ മലയാളം വിക്കിപ്പീഡിയ സജീവമായത്.\n"
     ]
    }
   ],
   "source": [
    "print(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "174a3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=text_data.replace('.','').replace('(','').replace(')','').replace('\\u200c','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "80d416f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'മലയാളം യൂണിക്കോഡും വിക്കീപീഡിയയുംമലയാളം പോലുള്ള ഭാഷകൾക്ക് കമ്പ്യൂട്ടറിൽ എഴുതാനും വായിക്കാനുമുപയോഗിക്കുന്ന ലിപിവ്യവസ്ഥകളിൽ ആദ്യമൊന്നും പൊതുവായ ഒരു മാനദണ്ഡമുണ്ടായിരുന്നില്ല അതിനാൽ തന്നെ ഇത്തരം ഭാഷയിൽ എഴുതുന്ന ലേഖനങ്ങൾ വായിക്കാൻ പ്രസ്തുത ലേഖനം എഴുതിയ ആൾ ഉപയോഗിച്ച ഫോണ്ടും കമ്പ്യൂട്ടർ വ്യവസ്ഥയും തന്നെ ഉപയോഗിക്കണം എന്ന സ്ഥിതി ആയിരുന്നു യുണികോഡ് എന്നറിയപ്പെടുന്ന കമ്പ്യൂട്ടർ ലിപിവ്യവസ്ഥ വന്നതോടുകൂടി മലയാളം കമ്പ്യൂട്ടറിനു വഴങ്ങുന്ന ഒന്നായി മലയാളം യൂണിക്കോഡ് അക്ഷരവിഭാഗം സാർവത്രികമായി ഉപയോഗിക്കുവാൻ തുടങ്ങിയതോടെയാണ് മലയാളം വിക്കിപ്പീഡിയ സജീവമായത്'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "4eb222da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "f9164b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "a342eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "39a6b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "c3912820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['മലയാളം',\n",
       " 'യൂണിക്കോഡും',\n",
       " 'വിക്കീപീഡിയയുംമലയാളം',\n",
       " 'പോലുള്ള',\n",
       " 'ഭാഷകൾക്ക്',\n",
       " 'കമ്പ്യൂട്ടറിൽ',\n",
       " 'എഴുതാനും',\n",
       " 'വായിക്കാനുമുപയോഗിക്കുന്ന',\n",
       " 'ലിപിവ്യവസ്ഥകളിൽ',\n",
       " 'ആദ്യമൊന്നും',\n",
       " 'പൊതുവായ',\n",
       " 'ഒരു',\n",
       " 'മാനദണ്ഡമുണ്ടായിരുന്നില്ല',\n",
       " 'അതിനാൽ',\n",
       " 'തന്നെ',\n",
       " 'ഇത്തരം',\n",
       " 'ഭാഷയിൽ',\n",
       " 'എഴുതുന്ന',\n",
       " 'ലേഖനങ്ങൾ',\n",
       " 'വായിക്കാൻ',\n",
       " 'പ്രസ്തുത',\n",
       " 'ലേഖനം',\n",
       " 'എഴുതിയ',\n",
       " 'ആൾ',\n",
       " 'ഉപയോഗിച്ച',\n",
       " 'ഫോണ്ടും',\n",
       " 'കമ്പ്യൂട്ടർ',\n",
       " 'വ്യവസ്ഥയും',\n",
       " 'തന്നെ',\n",
       " 'ഉപയോഗിക്കണം',\n",
       " 'എന്ന',\n",
       " 'സ്ഥിതി',\n",
       " 'ആയിരുന്നു',\n",
       " 'യുണികോഡ്',\n",
       " 'എന്നറിയപ്പെടുന്ന',\n",
       " 'കമ്പ്യൂട്ടർ',\n",
       " 'ലിപിവ്യവസ്ഥ',\n",
       " 'വന്നതോടുകൂടി',\n",
       " 'മലയാളം',\n",
       " 'കമ്പ്യൂട്ടറിനു',\n",
       " 'വഴങ്ങുന്ന',\n",
       " 'ഒന്നായി',\n",
       " 'മലയാളം',\n",
       " 'യൂണിക്കോഡ്',\n",
       " 'അക്ഷരവിഭാഗം',\n",
       " 'സാർവത്രികമായി',\n",
       " 'ഉപയോഗിക്കുവാൻ',\n",
       " 'തുടങ്ങിയതോടെയാണ്',\n",
       " 'മലയാളം',\n",
       " 'വിക്കിപ്പീഡിയ',\n",
       " 'സജീവമായത്']"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1d1271e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = np.unique(tokens)\n",
    "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))#finding index of uniqe words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a2798c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'അക്ഷരവിഭാഗം'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "64a148ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "46086e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'അക്ഷരവിഭാഗം': 0,\n",
       " 'അതിനാൽ': 1,\n",
       " 'ആദ്യമൊന്നും': 2,\n",
       " 'ആയിരുന്നു': 3,\n",
       " 'ആൾ': 4,\n",
       " 'ഇത്തരം': 5,\n",
       " 'ഉപയോഗിക്കണം': 6,\n",
       " 'ഉപയോഗിക്കുവാൻ': 7,\n",
       " 'ഉപയോഗിച്ച': 8,\n",
       " 'എന്ന': 9,\n",
       " 'എന്നറിയപ്പെടുന്ന': 10,\n",
       " 'എഴുതാനും': 11,\n",
       " 'എഴുതിയ': 12,\n",
       " 'എഴുതുന്ന': 13,\n",
       " 'ഒന്നായി': 14,\n",
       " 'ഒരു': 15,\n",
       " 'കമ്പ്യൂട്ടറിനു': 16,\n",
       " 'കമ്പ്യൂട്ടറിൽ': 17,\n",
       " 'കമ്പ്യൂട്ടർ': 18,\n",
       " 'തന്നെ': 19,\n",
       " 'തുടങ്ങിയതോടെയാണ്': 20,\n",
       " 'പൊതുവായ': 21,\n",
       " 'പോലുള്ള': 22,\n",
       " 'പ്രസ്തുത': 23,\n",
       " 'ഫോണ്ടും': 24,\n",
       " 'ഭാഷകൾക്ക്': 25,\n",
       " 'ഭാഷയിൽ': 26,\n",
       " 'മലയാളം': 27,\n",
       " 'മാനദണ്ഡമുണ്ടായിരുന്നില്ല': 28,\n",
       " 'യുണികോഡ്': 29,\n",
       " 'യൂണിക്കോഡും': 30,\n",
       " 'യൂണിക്കോഡ്': 31,\n",
       " 'ലിപിവ്യവസ്ഥ': 32,\n",
       " 'ലിപിവ്യവസ്ഥകളിൽ': 33,\n",
       " 'ലേഖനം': 34,\n",
       " 'ലേഖനങ്ങൾ': 35,\n",
       " 'വന്നതോടുകൂടി': 36,\n",
       " 'വഴങ്ങുന്ന': 37,\n",
       " 'വായിക്കാനുമുപയോഗിക്കുന്ന': 38,\n",
       " 'വായിക്കാൻ': 39,\n",
       " 'വിക്കിപ്പീഡിയ': 40,\n",
       " 'വിക്കീപീഡിയയുംമലയാളം': 41,\n",
       " 'വ്യവസ്ഥയും': 42,\n",
       " 'സജീവമായത്': 43,\n",
       " 'സാർവത്രികമായി': 44,\n",
       " 'സ്ഥിതി': 45}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "7ddb9b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "bf74b64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['മലയാളം', 'യൂണിക്കോഡും', 'വിക്കീപീഡിയയുംമലയാളം']\n",
      "['യൂണിക്കോഡും', 'വിക്കീപീഡിയയുംമലയാളം', 'പോലുള്ള']\n",
      "പോലുള്ള\n"
     ]
    }
   ],
   "source": [
    "#Creating input and output from the text data for training modle\n",
    "WORD_LENGTH = 3\n",
    "prev_words = []\n",
    "next_words = []\n",
    "for i in range(len(tokens) - WORD_LENGTH):\n",
    "    prev_words.append(tokens[i:i + WORD_LENGTH])\n",
    "    next_words.append(tokens[i + WORD_LENGTH])\n",
    "print(prev_words[0])\n",
    "print(prev_words[1])\n",
    "print(next_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "c2038e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prev_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "ebb3188b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "7802e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the words into numerical data\n",
    "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)))\n",
    "Y = np.zeros((len(next_words), len(unique_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "26724fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 3, 46)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "bc8f1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For getting better understanding for model training ,both x and y where the word is present ,on that index representing with 1 and all the other are in zeros,like one hot encoding\n",
    "for i, each_words in enumerate(prev_words):\n",
    "    for j, each_word in enumerate(each_words):\n",
    "        X[i, j, unique_word_index[each_word]] = 1\n",
    "    Y[i, unique_word_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "34b4a106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0]#here we can see that where the word is present ,at that position representing 1 instead of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0dfae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "e55630cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
    "model.add(Dense(len(unique_words)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "2854d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "0228ab5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3.8255 - accuracy: 0.0222 - val_loss: 3.9061 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.5774 - accuracy: 0.9556 - val_loss: 4.0325 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1633 - accuracy: 0.9111 - val_loss: 4.4227 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2678 - accuracy: 0.6667 - val_loss: 4.9506 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0522 - accuracy: 1.0000 - val_loss: 7.2624 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8021 - accuracy: 0.8000 - val_loss: 5.6408 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6116 - accuracy: 0.8444 - val_loss: 5.4543 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2718 - accuracy: 0.9556 - val_loss: 5.9299 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1499 - accuracy: 1.0000 - val_loss: 6.1425 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 6.3692 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 6.5793 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 6.7258 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 6.8574 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 6.9635 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 7.0557 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 7.1359 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 7.2069 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 7.2707 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 7.3286 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 7.3816 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=20, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "b3f9052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    \n",
    "    x = np.zeros((1, WORD_LENGTH, len(unique_words)))\n",
    "    for t, word in enumerate(text.split()):\n",
    "        print(word)\n",
    "        x[0, t, unique_word_index[word]] = 1\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e3c69d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "0cb6c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completions(text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [unique_words[idx] for idx in next_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80724cc9",
   "metadata": {},
   "source": [
    "### Taking input from user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "39e29e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Malayalam textമാനദണ്ഡമുണ്ടായിരുന്നില്ല അതിനാൽ തന്നെ\n"
     ]
    }
   ],
   "source": [
    "q=input(\"Enter the Malayalam text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "31992511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'മാനദണ്ഡമുണ്ടായിരുന്നില്ല അതിനാൽ തന്നെ'"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "76df2552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct sentence:  മാനദണ്ഡമുണ്ടായിരുന്നില്ല അതിനാൽ തന്നെ\n",
      "Sequence:  മാനദണ്ഡമുണ്ടായിരുന്നില്ല അതിനാൽ തന്നെ\n",
      "മാനദണ്ഡമുണ്ടായിരുന്നില്ല\n",
      "അതിനാൽ\n",
      "തന്നെ\n",
      "next possible words:  ['ഇത്തരം', 'തന്നെ', 'ഭാഷയിൽ', 'ഉപയോഗിക്കണം', 'ഒന്നായി']\n"
     ]
    }
   ],
   "source": [
    "#q =  \"മലയാളം യൂണിക്കോഡും വിക്കീപീഡിയയുംമലയാളം പോലുള്ള ഭാഷകൾക്ക് കമ്പ്യൂട്ടറിൽ എഴുതാനും\"\n",
    "print(\"correct sentence: \",q)\n",
    "seq = \" \".join(word_tokenize(q)[0:3])\n",
    "print(\"Sequence: \",seq)\n",
    "print(\"next possible words: \", predict_completions(seq, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e88dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
